<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Pre-Training | Jing Shao (邵婧)</title><link>https://amandajshao.github.io/tag/pre-training/</link><atom:link href="https://amandajshao.github.io/tag/pre-training/index.xml" rel="self" type="application/rss+xml"/><description>Pre-Training</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Fri, 11 Mar 2022 00:00:00 +0000</lastBuildDate><image><url>https://amandajshao.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Pre-Training</title><link>https://amandajshao.github.io/tag/pre-training/</link></image><item><title>Democratizing Contrastive Language-Image Pre-training: A CLIP Benchmark of Data, Model, and Supervision</title><link>https://amandajshao.github.io/publication/cui-democratizing-2022/</link><pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate><guid>https://amandajshao.github.io/publication/cui-democratizing-2022/</guid><description/></item></channel></rss>