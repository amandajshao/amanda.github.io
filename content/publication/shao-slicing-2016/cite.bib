@inproceedings{shao_slicing_2016,
 abstract = {Learning and capturing both appearance and dynamic representations are pivotal for crowd video understanding. Convolutional Neural Networks (CNNs) have shown its remarkable potential in learning appearance representations from images. However, the learning of dynamic representation, and how it can be effectively combined with appearance features for video analysis, remains an open problem. In this study, we propose a novel spatio-temporal CNN, named Slicing CNN (S-CNN), based on the decomposition of 3D feature maps into 2D spatio-and 2D temporal-slices representations. The decomposition brings unique advantages: (1) the model is capable of capturing dynamics of different semantic units such as groups and objects, (2) it learns separated appearance and dynamic representations while keeping proper interactions between them, and (3) it exploits the selectiveness of spatial filters to discard irrelevant background clutter for crowd understanding. We demonstrate the effectiveness of the proposed S-CNN model on the WWW crowd video dataset for attribute recognition and observe significant performance improvements to the state-of-the-art methods (62.55% from 51.84% [21]).},
 author = {Shao, Jing and Loy, Chen Change and Kang, Kai and Wang, Xiaogang},
 booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 doi = {10.1109/CVPR.2016.606},
 file = {IEEE Xplore Abstract Record:/Users/lucasjing/Zotero/storage/DKIDBWAV/7780975.html:text/html},
 keywords = {Dynamics, Feature extraction, Ice, Semantics, Three-dimensional displays, Two dimensional displays, Visualization},
 month = {June},
 note = {ISSN: 1063-6919},
 pages = {5620--5628},
 title = {Slicing Convolutional Neural Network for Crowd Video Understanding},
 year = {2016}
}

