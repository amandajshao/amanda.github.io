---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Improving Deep Visual Representation for Person Re-identification by Global
  and Local Image-language Association
subtitle: ''
summary: ''
authors:
- Dapeng Chen
- Hongsheng Li
- Xihui Liu
- Yantao Shen
- Jing Shao
- Zejian Yuan
- Xiaogang Wang
author_notes:
- 
- "Corresponding author"
tags: ["Person Re-identification", "Vision and Language"]
categories: ["Visual Surveillance"]
date: '2018-01-01'
lastmod: 2022-08-26T23:26:31+08:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-08-26T15:26:31.244365Z'
publication_types:
- '1'
abstract: Person re-identiﬁcation is an important task that requires learning discriminative
  visual features for distinguishing diﬀerent person identities. Diverse auxiliary
  information has been utilized to improve the visual feature learning. In this paper,
  we propose to exploit natural language description as additional training supervisions
  for eﬀective visual features. Compared with other auxiliary information, language
  can describe a speciﬁc person from more compact and semantic visual aspects, thus
  is complementary to the pixel-level image data. Our method not only learns better
  global visual feature with the supervision of the overall description but also enforces
  semantic consistencies between local visual and linguistic features, which is achieved
  by building global and local image-language associations. The global image-language
  association is established according to the identity labels, while the local association
  is based upon the implicit correspondences between image regions and noun phrases.
  Extensive experiments demonstrate the eﬀectiveness of employing language as training
  supervisions with the two association schemes. Our method achieves state-of-the-art
  performance without utilizing any auxiliary information during testing and shows
  better performance than other joint embedding methods for the image-language association.
publication: 'European Conference on Computer Vision (**ECCV**), 2018'
doi: 10.1007/978-3-030-01270-0_4

url_pdf: "https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Dapeng_Chen_Improving_Deep_Visual_ECCV_2018_paper.pdf"
url_code: 
url_dataset:
url_poster:
url_project:
url_slides:
url_source:
url_video:

---
