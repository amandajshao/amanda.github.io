---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'INTERN: A New Learning Paradigm Towards General Vision'
subtitle: ''
summary: ''
authors:
- Jing Shao
- Siyu Chen
- Yangguang Li
- Kun Wang
- Zhenfei Yin
- Yinan He
- Jianing Teng
- Qinghong Sun
- Mengya Gao
- Jihao Liu
- Gengshi Huang
- Guanglu Song
- Yichao Wu
- Yuming Huang
- Fenggang Liu
- Huan Peng
- Shuo Qin
- Chengyu Wang
- Yujie Wang
- Conghui He
- Ding Liang
- Yu Liu
- Fengwei Yu
- Junjie Yan
- Dahua Lin
- Xiaogang Wang
- Yu Qiao
author_notes:
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
- "Equal contribution"
tags: []
categories: []
date: '2021-11-01'
lastmod: 2022-08-26T23:26:33+08:00
featured: true
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: ["cross-modality-learning"]
publishDate: '2022-08-26T15:26:33.674136Z'
publication_types:
- '3'
abstract: 'Enormous waves of technological innovations over the past several years, marked by the advances in AI technologies, are profoundly reshaping the industry and the society. However, down the road, a key challenge awaits us, that is, our capability of meeting rapidly-growing scenario-specific demands is severely limited by the cost of acquiring a commensurate amount of training data. This difficult situation is in essence due to limitations of the mainstream learning paradigm: we need to train a new model for each new scenario, based on a large quantity of well-annotated data and commonly from scratch. In tackling this fundamental problem, we move beyond and develop a new learning paradigm named INTERN. By learning with supervisory signals from multiple sources in multiple stages, the model being trained will develop strong generalizability. We evaluate our model on 26 well-known datasets that cover four categories of tasks in computer vision. In most cases, our models, adapted with only 10% of the training data in the target domain, outperform the counterparts trained with the full set of data, often by a significant margin. This is an important step towards a promising prospect where such a model with general vision capability can dramatically reduce our reliance on data, thus expediting the adoption of AI technologies. Furthermore, revolving around our new paradigm, we also introduce a new data system, a new architecture, and a new benchmark, which, together, form a general vision ecosystem to support its future development in an open and inclusive manner. See project website at https://opengvlab.shlab.org.cn .'
publication: '*CoRR*'

url_pdf: "http://arxiv.org/abs/2111.08687"
url_code:
url_dataset: 
url_poster:
url_project: "https://opengvlab.shlab.org.cn"
url_slides:
url_source:
url_video:
---
