---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Learning Scene-Independent Group Descriptors for Crowd Understanding
subtitle: ''
summary: ''
authors:
- Jing Shao
- Chen Change Loy
- Xiaogang Wang
tags:
- Circuit stability
- Crowded scene understanding
- Feature extraction
- group-property analysis
- Hidden Markov models
- Psychology
- Robustness
- Stability analysis
- video analysis
- Visualization
categories: []
date: '2017-06-01'
lastmod: 2022-08-26T23:26:31+08:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: ["crowd-behavior-understanding"]
publishDate: '2022-08-26T15:26:31.120690Z'
publication_types:
- '2'
abstract: Groups are the primary entities that make up a crowd. Understanding group-level
  dynamics and properties is thus scientifically important and practically useful
  in a wide range of applications, especially for crowd understanding. In this paper,
  we show that fundamental group-level properties, such as intra-group stability and
  inter-group conflict, can be systematically quantified by visual descriptors. This
  is made possible through learning a novel collective transition prior, which leads
  to a robust approach for group segregation in public spaces. From the former, we
  further devise a rich set of group-property visual descriptors. These descriptors
  are scene-independent and can be effectively applied to public scenes with a variety
  of crowd densities and distributions. Extensive experiments on hundreds of public
  scene video clips demonstrate that such property descriptors are complementary to
  each other, scene-independent, and they convey critical information on physical
  states of a crowd. The proposed group-level descriptors show promising results and
  potentials in multiple applications, including crowd dynamic monitoring, crowd video
  classification, and crowd video retrieval.
publication: 'IEEE Transactions on Circuits and Systems for Video Technology (**IEEE T-CSVT**), 2017'
doi: 10.1109/TCSVT.2016.2539878
---
