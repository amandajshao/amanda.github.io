---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'Thinking in Frequency: Face Forgery Detection by Mining Frequency-Aware Clues'
subtitle: ''
summary: ''
authors:
- Yuyang Qian
- Guojun Yin
- Lu Sheng
- Zixuan Chen
- Jing Shao
author_notes:
- "Equal contribution"
- "Equal contribution, Corresponding author"
- "Corresponding author"
tags: []
categories: []
date: '2020-10-01'
lastmod: 2022-08-26T23:26:27+08:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: ["face-forgery-detection"]
publishDate: '2022-08-26T15:26:27.794230Z'
publication_types:
- '1'
abstract: As realistic facial manipulation technologies have achieved remarkable progress,
  social concerns about potential malicious abuse of these technologies bring out
  an emerging research topic of face forgery detection. However, it is extremely challenging
  since recent advances are able to forge faces beyond the perception ability of human
  eyes, especially in compressed images and videos. We ﬁnd that mining forgery patterns
  with the awareness of frequency could be a cure, as frequency provides a complementary
  viewpoint where either subtle forgery artifacts or compression errors could be well
  described. To introduce frequency into the face forgery detection, we propose a
  novel Frequency in Face Forgery Network (F3-Net), taking advantages of two diﬀerent
  but complementary frequency-aware clues, 1) frequency-aware decomposed image components,
  and 2) local frequency statistics, to deeply mine the forgery patterns via our two-stream
  collaborative learning framework. We apply DCT as the applied frequency-domain transformation.
  Through comprehensive studies, we show that the proposed F3-Net signiﬁcantly outperforms
  competing state-of-the-art methods on all compression qualities in the challenging
  FaceForensics++ dataset, especially wins a big lead upon low-quality media.
publication: 'European Conference on Computer Vision (**ECCV**), 2020'
doi: 10.1007/978-3-030-58610-2_6

url_pdf: "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590613.pdf"

---
