---
# Display name
title: Jing Shao

# Is this the primary user of the site?
superuser: true

# Role/position/tagline
role: Research Scientist

# Organizations/Affiliations to show in About widget
organizations:
  - name: Shanghai Artificial Intelligence Laboratory 
    url: https://www.shlab.org.cn/

# Short bio (displayed in user profile at end of posts)
bio: Research Scientist at Shanghai Artificial Intelligence Laboratory

# Interests to show in About widget
interests: []
  # - Generation/Recognition for Face, Body and Scene
  # - Vision and Language
  # - General Vision Representation

# Education to show in About widget
education: []
  # courses:
  #   - course: PhD in Artificial Intelligence
  #     institution: Stanford University
  #     year: 2012
  #   - course: MEng in Artificial Intelligence
  #     institution: Massachusetts Institute of Technology
  #     year: 2009
  #   - course: BSc in Artificial Intelligence
  #     institution: Massachusetts Institute of Technology
  #     year: 2008

# Social/Academic Networking
# For available icons, see: https://wowchemy.com/docs/getting-started/page-builder/#icons
#   For an email link, use "fas" icon pack, "envelope" icon, and a link in the
#   form "mailto:your-email@example.com" or "/#contact" for contact widget.
social:
- icon: envelope
  icon_pack: fas
  link: '/#contact'
- icon: google-scholar  # Alternatively, use `google-scholar` icon from `ai` icon pack
  icon_pack: ai
  link: https://scholar.google.com.hk/citations?hl=zh-CN&user=VU5ObUwAAAAJ

# Link to a PDF of your resume/CV.
# To use: copy your resume to `static/uploads/resume.pdf`, enable `ai` icons in `params.toml`,
# and uncomment the lines below.
# - icon: cv
#   icon_pack: ai
#   link: uploads/jshao_cv_v2.pdf

# Enter email to display Gravatar (if Gravatar enabled in Config)
email: 'amandashaojing@gmail.com'

# Highlight the author in author lists? (true/false)
highlight_name: true
---

<!-- Jing Shao is currently at [Shanghai Artificial Intelligence Laboratory](https://www.shlab.org.cn/) as a research scientist focusing on multi-modal foundation models and agents, with special interests in understanding various properties of current models beyond their accuracy, such as explainability, robustness, safety and generalization, towards the reliableness of AI systems. She is also an Adjunt Ph.D. supervisor at the [Shanghai Jiao Tong University](https://www.sjtu.edu.cn/), and a Co-PI of [S-Lab](https://www.ntu.edu.sg/s-lab) in [Nanyang Technological University](https://www.ntu.edu.sg/). 

She received her Ph.D. (2016) in Electronic Engineering from [The Chinese University of Hong Kong (CUHK)](http://www.cuhk.edu.hk/english/index.html), supervised by [Prof. Xiaogang Wang](http://www.ee.cuhk.edu.hk/~xgwang/), and work closely with [Prof. Chen Change Loy](https://www.mmlab-ntu.com/person/ccloy/index.html) and the [Multimedia Lab (MMLab)](http://mmlab.ie.cuhk.edu.hk/) led by [Prof. Xiaoou Tang](https://www.ie.cuhk.edu.hk/people/xotang.shtml). She has published 40+ peer-reviewed articles (including 20 first/co-first/corresponding author papers) in top-tier conferences and journals such as TPAMI, IJCV, ICML, ICLR, NeurIPS and CVPR, with 7300+ citations in Google Scholar. She serves as the reviewer of IJCV, T-PAMI, T-CSVT, T-MM, T-ITS, and CVIU, and reviewed CVPR, ICCV, ECCV, NeurIPS, ICLR, AAAI, IJCAI, and ACM MM. -->


Jing Shao is a Research Scientist with [Shanghai Artificial Intelligence Laboratory, China](https://www.shlab.org.cn). She is Co-Director of the [Center of Safe & Trustworthy AI](https://ai45.shlab.org.cn/). She is also an Adjunct Ph.D. supervisor at [Shanghai Jiao Tong University](https://www.sjtu.edu.cn/) and [Fudan University](https://www.fudan.edu.cn/). She received her Ph.D. (2016) from  [Multimedia Lab (MMLab)](http://mmlab.ie.cuhk.edu.hk/), [The Chinese University of Hong Kong (CUHK)](http://www.cuhk.edu.hk/english/index.html), supervised by [Prof. Xiaogang Wang](http://www.ee.cuhk.edu.hk/~xgwang/), and worked closely with [Prof. Chen Change Loy](https://www.mmlab-ntu.com/person/ccloy/index.html) and [Prof. Xiaoou Tang](https://www.ie.cuhk.edu.hk/people/xotang.shtml). Prior to joining Shanghai AI Lab, she served as a Research Director at SenseTime from 2016 to 2023.

Her research interests focus on multi-modal foundation models and agents, with special interests in understanding various properties of current models beyond their accuracy, such as safety, explainability, robustness, and generalization, towards the reliableness of AI systems. She has published 50+ peer-reviewed articles in top-tier conferences and journals such as TPAMI, IJCV, ICML, ICLR, NeurIPS, CVPR, and ACL, with 11500+ citations in Google Scholar. She is recognized as Stanford Top 2% Worldwide Scientist in 2024, and received ACL 2024 Outstanding Paper Award.


<span style="color:red">**We are actively hiring Full-time Researchers/Interns working together on safety/robustness/explainablity of generative models and agents. I am also looking for talented students targeted to Master or Ph.D. degree. Please drop me an email if you are interested.**</span>

<!-- She is currently a Research Director in [SenseTime Group Limited](https://www.sensetime.com), and an Adjunct Ph.D. Supervisor at the [Shanghai Jiao Tong University](https://www.sjtu.edu.cn/). She is a Co-PI of [S-Lab]() in [Nanyang Technological University](https://www.ntu.edu.sg/). She received her Ph.D. (2016) in Electronic Engineering from [The Chinese University of Hong Kong (CUHK)](http://www.cuhk.edu.hk/english/index.html), supervised by [Prof. Xiaogang Wang](http://www.ee.cuhk.edu.hk/~xgwang/), and work closely with [Prof. Chen Change Loy](https://www.mmlab-ntu.com/person/ccloy/index.html) and the [Multimedia Lab (MMLab)](http://mmlab.ie.cuhk.edu.hk/) led by [Prof. Xiaoou Tang](https://www.ie.cuhk.edu.hk/people/xotang.shtml). -->

<!-- Her research interests lies at the computer vision and multimedia, with focus on generating, perceiving, and understanding the 2D/3D visual world, for instance, -->

<!-- - Multimodal LLM -->
<!-- - General Vision Representation -->
<!-- - Human-centric Understanding and Generation (Face, Body, Scene, and *etc*). -->

