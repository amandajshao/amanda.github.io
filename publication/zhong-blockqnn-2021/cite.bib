@article{zhong_blockqnn_2021,
 abstract = {Convolutional neural networks have gained a remarkable success in computer vision. However, most popular network architectures are hand-crafted and usually require expertise and elaborate design. In this paper, we provide a block-wise network generation pipeline called BlockQNN which automatically builds high-performance networks using the Q-Learning paradigm with epsilon-greedy exploration strategy. The optimal network block is constructed by the learning agent which is trained to choose component layers sequentially. We stack the block to construct the whole auto-generated network. To accelerate the generation process, we also propose a distributed asynchronous framework and an early stop strategy. The block-wise generation brings unique advantages: (1) it yields state-of-the-art results in comparison to the hand-crafted networks on image classification, particularly, the best network generated by BlockQNN achieves 2.35 percent top-1 error rate on CIFAR-10. (2) it offers tremendous reduction of the search space in designing networks, spending only 3 days with 32 GPUs. A faster version can yield a comparable result with only 1 GPU in 20 hours. (3) it has strong generalizability in that the network built on CIFAR also performs well on the larger-scale dataset. The best network achieves very competitive accuracy of 82.0 percent top-1 and 96.0 percent top-5 on ImageNet.},
 author = {Zhong, Zhao and Yang, Zichen and Deng, Boyang and Yan, Junjie and Wu, Wei and Shao, Jing and Liu, Cheng-Lin},
 doi = {10.1109/TPAMI.2020.2969193},
 file = {IEEE Xplore Abstract Record:/Users/lucasjing/Zotero/storage/RTI8PPA5/8966988.html:text/html;Submitted Version:/Users/lucasjing/Zotero/storage/XGTIUGPG/Zhong et al. - 2021 - BlockQNN Efficient Block-Wise Neural Network Arch.pdf:application/pdf},
 issn = {1939-3539},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 keywords = {Acceleration, AutoML, Computer architecture, Convolutional neural network, Graphics processing units, Indexes, Network architecture, neural architecture search, Neural networks, Q-learning, reinforcement learning, Task analysis},
 month = {July},
 note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
 number = {7},
 pages = {2314--2328},
 shorttitle = {BlockQNN},
 title = {BlockQNN: Efficient Block-Wise Neural Network Architecture Generation},
 volume = {43},
 year = {2021}
}

