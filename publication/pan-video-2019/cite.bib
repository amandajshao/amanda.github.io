@inproceedings{pan_video_2019,
 abstract = {This paper proposes the novel task of video generation conditioned on a SINGLE semantic label map, which provides a good balance between ﬂexibility and quality in the generation process. Different from typical end-to-end approaches, which model both scene content and dynamics in a single step, we propose to decompose this difﬁcult task into two sub-problems. As current image generation methods do better than video generation in terms of detail, we synthesize high quality content by only generating the ﬁrst frame. Then we animate the scene based on its semantic meaning to obtain temporally coherent video, giving us excellent results overall. We employ a cVAE for predicting optical ﬂow as a beneﬁcial intermediate step to generate a video sequence conditioned on the initial single frame. A semantic label map is integrated into the ﬂow prediction module to achieve major improvements in the image-to-video generation process. Extensive experiments on the Cityscapes dataset show that our method outperforms all competing methods. The source code will be released on https://github.com/junting/seg2vid.},
 address = {Long Beach, CA, USA},
 author = {Pan, Junting and Wang, Chengyu and Jia, Xu and Shao, Jing and Sheng, Lu and Yan, Junjie and Wang, Xiaogang},
 booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
 doi = {10.1109/CVPR.2019.00385},
 file = {Pan et al. - 2019 - Video Generation From Single Semantic Label Map.pdf:/Users/lucasjing/Zotero/storage/FDP7NVUN/Pan et al. - 2019 - Video Generation From Single Semantic Label Map.pdf:application/pdf},
 isbn = {978-1-72813-293-8},
 language = {en},
 month = {June},
 pages = {3728--3737},
 publisher = {IEEE},
 title = {Video Generation From Single Semantic Label Map},
 url = {https://ieeexplore.ieee.org/document/8953551/},
 urldate = {2022-08-22},
 year = {2019}
}

